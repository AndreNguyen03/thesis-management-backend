import { Injectable, OnModuleInit, Inject } from '@nestjs/common'
import { InjectModel } from '@nestjs/mongoose'
import { Model } from 'mongoose'
import { ConfigType } from '@nestjs/config'
import { ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings } from '@langchain/google-genai'
import { MongoDBAtlasVectorSearch } from '@langchain/mongodb'
import { googleAIConfig } from '../../config/googleai.config'
import { TopicVector } from './schemas/topic_vectore.schemas'
import { Topic } from '../topics/schemas/topic.schemas'
import { ChatPromptTemplate } from '@langchain/core/prompts'

import { createStuffDocumentsChain } from 'langchain/chains/combine_documents'
import { createRetrievalChain } from 'langchain/chains/retrieval'
@Injectable()
export class SearchService implements OnModuleInit {
    // 1. Khai b√°o property vectorStore ƒë·ªÉ d√πng ƒë∆∞·ª£c ·ªü c√°c h√†m kh√°c trong class
    private vectorStore: MongoDBAtlasVectorSearch

    constructor(
        @InjectModel(TopicVector.name)
        private readonly topicVectorModel: Model<TopicVector>,
        @InjectModel(Topic.name)
        private readonly topicModel: Model<Topic>,
        @Inject(googleAIConfig.KEY)
        private readonly googleAIConfiguration: ConfigType<typeof googleAIConfig>
    ) {}

    async onModuleInit() {
        try {
            const embeddings = new GoogleGenerativeAIEmbeddings({
                modelName: 'text-embedding-003',
                apiKey: this.googleAIConfiguration.apiKey
            })

            this.vectorStore = new MongoDBAtlasVectorSearch(embeddings, {
                collection: this.topicVectorModel.collection as any,
                indexName: 'search_topic_vector_index',
                textKey: 'text_content',
                embeddingKey: 'embedding'
            })

            console.log('ü§ñ Chatbot Service ƒë√£ kh·ªüi t·∫°o Vector Store th√†nh c√¥ng!')
        } catch (error) {
            console.error('‚ùå L·ªói kh·ªüi t·∫°o Chatbot Service:', error)
        }
    }

    async syncData() {
        const rawTopics = await this.topicModel.find({ deleted_at: null }).exec()
        if (rawTopics.length === 0) {
            console.log('Kh√¥ng c√≥ ƒë·ªÅ t√†i n√†o')
            return
        }

        // ... (Code map docs gi·ªØ nguy√™n) ...
        // const docs = rawTopics.map(
        //     (topic) =>
        //         new Document({
        //             pageContent: `T√™n ƒë·ªÅ t√†i b·∫±ng ti·∫øng Anh: ${topic.titleEng}. T√™n ƒë·ªÅ t√†i b·∫±ng ti·∫øng Vi·ªát: ${topic.titleVN}
        //             . M√¥ t·∫£: ${topic.description}. GVHD: ${topic.lecturer}`,
        //             metadata: { original_id: topic._id, status: topic.status }
        //         })
        // )

        // // QUAN TR·ªåNG: Ph·∫£i x√≥a d·ªØ li·ªáu vector C≈® (c·ªßa OpenAI) ƒëi v√¨ n√≥ kh√¥ng t∆∞∆°ng th√≠ch v·ªõi Google
        // //  await db.collection(this.VECTOR_COLLECTION_NAME).deleteMany({})

        // await this.vectorStore.addDocuments(docs)
        // console.log(`‚úÖ ƒê√£ ƒë·ªìng b·ªô xong ${docs.length} ƒë·ªÅ t√†i b·∫±ng Gemini Embeddings!`)
    }

    async searchWithDescription(description: string) {
        // 3. C·∫§U H√åNH CHAT MODEL GOOGLE (LLM)
        const model = new ChatGoogleGenerativeAI({
            model: 'gemini-1.5-flash',
            apiKey: this.googleAIConfiguration.apiKey,
            temperature: 0.7,
            maxOutputTokens: 1000
        })

        const prompt = ChatPromptTemplate.fromTemplate(`
      B·∫°n l√† Tr·ª£ l√Ω h·ªçc v·ª•. Tr·∫£ l·ªùi d·ª±a tr√™n context sau:
      <context>
      {context}
      </context>
      C√¢u h·ªèi: {input}
    `)

        const chain = await createRetrievalChain({
            retriever: this.vectorStore.asRetriever({ k: 3 }),
            combineDocsChain: await createStuffDocumentsChain({ llm: model, prompt })
        })

        const response = await chain.invoke({ input: description })

        return {
            answer: response.answer,
            related_topics: response.context.map((doc) => doc.metadata)
        }
    }
}
