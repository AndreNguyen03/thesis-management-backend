import { forwardRef, Injectable } from '@nestjs/common'
import { KnowledgeSource } from '../schemas/knowledge-source.schema'
import { InjectModel } from '@nestjs/mongoose'
import mongoose, { Model, Document } from 'mongoose'
import { PaginationProvider } from '../../../common/pagination-an/providers/pagination.provider'
import { RequestKnowledgeSourceDto } from '../dto/request-get-knowledge-source.dto'
import { Paginated } from '../../../common/pagination-an/interfaces/paginated.interface'
import { UpdateKnowledgeSourceDto } from '../dto/update-knowledge-source.dto'
import { pipeline } from 'stream'
import { GetTopicProvider } from '../../topics/providers/get-topic.provider'
import { TopicStatus } from '../../topics/enum'
import { PeriodPhaseName } from '../../periods/enums/period-phases.enum'
import { SourceType } from '../enums/source_type.enum'
import { GetEmbeddingProvider } from '../../chatbot/providers/get-embedding.provider'
import { CreateKnowledgeChunksProvider } from './create-knowledge-chunks.provider'
import { buildTopicSummary } from '../../recommend/utils/build-topic-summarize'
import { topicToContentString } from '../../topic_search/utils/get-topic-info-document'
import { RetrievalProvider } from '../../chatbot/providers/retrieval.provider'
import { KnowledgeChunk } from '../schemas/knowledge-chunk.schema'
import { Lecturer } from '../../../users/schemas/lecturer.schema'
import { buildProfileText } from '../utils/build-lecturer-profile.utils'
import { KnowledgeStatus } from '../enums/knowledge-status.enum'

@Injectable()
export class KnowledgeSourceService {
    constructor(
        private readonly paginationProvider: PaginationProvider,
        @InjectModel(KnowledgeChunk.name)
        private readonly knowledgeChunkModel: Model<KnowledgeChunk>,
        @InjectModel(Lecturer.name)
        private readonly lecturerModel: Model<Lecturer>,
        @InjectModel(KnowledgeSource.name)
        private readonly knowledgeSourceModel: Model<KnowledgeSource & Document>,
        private readonly getTopicProvider: GetTopicProvider,
        private readonly getEmbeddingProvider: GetEmbeddingProvider,
        private readonly knowledgeChunksProvider: CreateKnowledgeChunksProvider,
        private readonly retrievalProvider: RetrievalProvider
    ) {}
    async findAll(query: RequestKnowledgeSourceDto): Promise<Paginated<KnowledgeSource & Document>> {
        // pipeline getting Owner information
        let pipelineSub: any[] = []
        pipelineSub.push({
            $lookup: {
                from: 'users',
                localField: 'owner',
                foreignField: '_id',
                as: 'owner_info'
            }
        })
        pipelineSub.push({
            $addFields: {
                owner_info: { $arrayElemAt: ['$owner_info', 0] }
            }
        })
        // pipelineSub.push({ $unwind: { path: '$owner_info', preserveNullAndEmptyArrays: true } })

        // Implementation for fetching knowledge sources based on the query
        return await this.paginationProvider.paginateQuery(
            {
                limit: query.limit,
                page: query.page
            },
            this.knowledgeSourceModel,
            pipelineSub
        )
    }
    async updateKnowledgeSources(klid: string, query: UpdateKnowledgeSourceDto): Promise<KnowledgeSource | null> {
        const updatedKnowledgeSource = await this.knowledgeSourceModel
            .findByIdAndUpdate(klid, query, { new: true })
            .exec()
        return updatedKnowledgeSource ? updatedKnowledgeSource.toObject() : null
    }
    async syncTopicsDataToKnowledgeSource(periodId: string, userId: string): Promise<{ message: string }> {
        //l·∫•y c√°i ƒë·ªÅ t√†i ƒëang m·ªü ƒëƒÉng k√Ω trong k·ª≥ hi·ªán t·∫°i
        const registeringTopics = await this.getTopicProvider.getTopicsInPhase(periodId, {
            page: 1,
            limit: 0,
            phase: PeriodPhaseName.OPEN_REGISTRATION
        })
        //l·∫•y t·∫•t c·∫£ c√°c ƒë·ªÅ t√†i trong th∆∞ vi·ªán
        const topicsInLibrary = await this.getTopicProvider.getTopicsInLibrary({
            page: 1,
            limit: 0,
            status: TopicStatus.Archived
        })
        //x·ª≠ l√Ω ƒë·ªìng b·ªô d·ªØ li·ªáu ƒë·ªÅ t√†i v√†o knowledge source
        //...
        // S·ª≠ d·ª•ng updateOne v·ªõi upsert ƒë·ªÉ t·∫°o m·ªõi ho·∫∑c c·∫≠p nh·∫≠t
        for (const topic of registeringTopics.data) {
            await this.knowledgeSourceModel.updateOne(
                {
                    source_type: SourceType.TOPIC_REGISTERING,
                    source_location: topic._id
                },
                {
                    $set: {
                        source_type: SourceType.TOPIC_REGISTERING,
                        source_location: topic._id,
                        title: topic.titleVN,
                        description: 'ƒê·ªÅ t√†i trong ƒë·ª£t ƒëƒÉng k√Ω',
                        owner: userId,
                        status: 'ENABLED'
                    }
                },
                { upsert: true }
            )
            const sourceDoc = await this.knowledgeSourceModel.findOne({
                source_type: SourceType.TOPIC_REGISTERING,
                source_location: topic._id.toString()
            })

            if (sourceDoc) {
                console.log('sourceDoc', topic)
                const text = topicToContentString(topic)
                console.log('text', text)
                const embedding = await this.getEmbeddingProvider.getEmbedding(text)
                await this.knowledgeChunksProvider.createKnowledgeChunks([
                    {
                        source_id: sourceDoc._id.toString(),
                        text: text, // Make sure chunk is defined
                        plot_embedding_gemini_large: embedding // Make sure vector is defined
                    }
                ])
            }
        }
        for (const topic of topicsInLibrary.data) {
            await this.knowledgeSourceModel.updateOne(
                {
                    source_type: SourceType.TOPIC_LIBRARY,
                    source_location: topic._id
                },
                {
                    $set: {
                        source_type: SourceType.TOPIC_LIBRARY,
                        source_location: topic._id,
                        title: topic.titleVN,
                        description: 'ƒê·ªÅ t√†i trong th∆∞ vi·ªán ƒë·ªÅ t√†i',
                        owner: userId,
                        status: 'ENABLED'
                    }
                },
                { upsert: true }
            )
            const sourceDoc = await this.knowledgeSourceModel.findOne({
                source_type: SourceType.TOPIC_LIBRARY,
                source_location: topic._id.toString()
            })

            if (sourceDoc) {
                const text = topicToContentString(topic)
                const embedding = await this.getEmbeddingProvider.getEmbedding(text)
                await this.knowledgeChunksProvider.createKnowledgeChunks([
                    {
                        source_id: sourceDoc._id.toString(),
                        text: text, // Make sure chunk is defined
                        plot_embedding_gemini_large: embedding // Make sure vector is defined
                    }
                ])
            }
        }

        return {
            message: `ƒê√£ ƒë·ªìng b·ªô ${topicsInLibrary.data.length + registeringTopics.data.length} ƒë·ªÅ t√†i v√†o ngu·ªìn tri th·ª©c`
        }
    }
    async syncLecturerProfiles(userId: string): Promise<{ message: string }> {
        try {
            // X√≥a data c≈© (n·∫øu c√≥)
            const deleteResult = await this.knowledgeSourceModel.deleteMany({
                source_type: SourceType.LECTURER_PROFILE
            })
            console.log(`üóëÔ∏è  Deleted ${deleteResult.deletedCount} old lecturer knowledge sources\n`)

            // L·∫•y t·∫•t c·∫£ lecturers
            const lecturers = await this.lecturerModel
                .find()
                .populate('userId', 'fullName email bio')
                .populate('facultyId', 'name')
                .lean()

            console.log(`üìã Found ${lecturers.length} lecturers to index\n`)

            let successCount = 0
            let errorCount = 0

            for (const lecturer of lecturers) {
                try {
                    const user = lecturer.userId as any
                    const faculty = lecturer.facultyId as any

                    if (!user || !user.fullName) {
                        console.log(`‚ö†Ô∏è  Skipping lecturer ${lecturer._id} - no user data`)
                        continue
                    }

                    // T·∫°o profile text (gh√©p t·∫•t c·∫£ th√¥ng tin quan tr·ªçng)
                    const profileText = buildProfileText(lecturer, user, faculty)

                    console.log(`\nüë§ Processing: ${user.fullName}`)
                    console.log(`   üìù Profile length: ${profileText.length} chars`)

                    // T·∫°o embedding
                    const embedding = await this.getEmbeddingProvider.getEmbedding(profileText)
                    console.log(`   ‚úÖ Generated embedding (${embedding.length} dimensions)`)

                    // T·∫°o knowledge source
                    const knowledgeSource = await this.knowledgeSourceModel.create({
                        name: `Lecturer Profile - ${user.fullName}`,
                        description: `H·ªì s∆° gi·∫£ng vi√™n ${user.fullName}`,
                        source_type: SourceType.LECTURER_PROFILE,
                        source_location: user._id.toString(),
                        source_name: user.fullName,
                        source_url: null,
                        status: KnowledgeStatus.ENABLED,
                        metadata: {
                            title: lecturer.title,
                            faculty: faculty?.name || 'N/A',
                            email: user.email
                        },
                        owner: userId
                    })
                    console.log(`   üì¶ Created knowledge source: ${knowledgeSource._id}`)

                    // T·∫°o knowledge chunk
                    const chunk = await this.knowledgeChunkModel.create({
                        source_id: knowledgeSource._id,
                        text: profileText,
                        embedding: embedding,
                        metadata: {
                            lecturerId: lecturer._id.toString(),
                            userId: user._id.toString(),
                            title: lecturer.title,
                            faculty: faculty?.name || 'N/A',
                            researchInterests: lecturer.researchInterests || [],
                            publicationCount: lecturer.publications?.length || 0
                        }
                    })
                    console.log(`   ‚úÖ Created knowledge chunk: ${chunk._id}`)

                    successCount++
                } catch (error) {
                    console.error(`   ‚ùå Error processing lecturer ${lecturer._id}:`, error.message)
                    errorCount++
                }
            }

            console.log('\n' + '='.repeat(60))
            console.log('üìä INDEXING SUMMARY')
            console.log('='.repeat(60))
            console.log(`‚úÖ Successfully indexed: ${successCount} lecturers`)
            console.log(`‚ùå Failed: ${errorCount} lecturers`)
            console.log(`üì¶ Total: ${lecturers.length} lecturers`)
            console.log('='.repeat(60))

            // Verify data
            const totalChunks = await this.knowledgeChunkModel.countDocuments({
                'metadata.lecturerId': { $exists: true }
            })
            console.log(`\nüîç Verification: Found ${totalChunks} lecturer chunks in database`)
        } catch (error) {
            console.error('‚ùå Fatal error:', error)
        } finally {
            console.log('\n‚úÖ Script completed')
        }
        return { message: `ƒê√£ ƒë·ªìng b·ªô h·ªì s∆° c·ªßa gi·∫£ng vi√™n v√†o ngu·ªìn tri th·ª©c` }
    }
    async semanticSearchKnowledgeSources(query: string): Promise<KnowledgeChunk[]> {
        const embedding = await this.getEmbeddingProvider.getEmbedding(query)
        return await this.retrievalProvider.searchSimilarDocuments(embedding, {
            limit: 20,
            sourceTypes: [SourceType.TOPIC_LIBRARY, SourceType.TOPIC_REGISTERING]
        })
    }
}
